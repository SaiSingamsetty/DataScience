x = c(1,5)
dataset2 = dataset[,-x]
names(dataset2)
View(dataset)
View(dataset)
View(dataset2)
View(dataset2)
#Assigning correct datatypes
class(dataset2$CreditCard)
table(dataset2$CreditCard)
dataset2$CreditCard = as.factor(dataset2$CreditCard)
#Assigning correct datatypes
class(dataset2$Online)
table(dataset2$Online)
dataset2$Online = as.factor(dataset2$Online)
#Assigning correct datatypes
class(dataset2$CD.Account)
table(dataset2$CD.Account)
#Assigning correct datatypes
class(dataset2$CD.Account)
table(dataset2$CD.Account)
dataset2$CD.Account = as.factor(dataset2$CD.Account)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
#removing unnecessary columns
x = c(1,5)
dataset2 = dataset[,-x]
names(dataset2)
#Assigning correct datatypes
str(dataset2)
#Outliers
boxplot(dataset2)
boxplot(dataset2$Personal.Loan)
y = summary(dataset2$Income)
top = y[5] + (1.5 * IQR(dataset2$Income))
dataset2$Income = ifelse(dataset2$Income > top, top, dataset2$Income)
boxplot(dataset2$CCAvg)
y = summary(dataset2$CCAvg)
top = y[5] + (1.5 * IQR(dataset2$CCAvg))
dataset2$CCAvg = ifelse(dataset2$CCAvg > top, top, dataset2$CCAvg)
boxplot(dataset2$CCAvg)
#Outliers
boxplot(dataset2)
y = summary(dataset2$Mortgage)
boxplot(dataset2$Mortgage)
y = summary(dataset2$Mortgage)
top = y[5] + (1.5 * IQR(dataset2$Mortgage))
dataset2$Mortgage = ifelse(dataset2$Mortgage > top, top, dataset2$Mortgage)
names(dataset2)
cor(dataset2[,c(1,2,3,4,5,6,7,8)])
cor(dataset2)
corrplot(cor(dataset2), 'number')
#train test split
set.seed(111)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
model1 = glm(Personal.Loan~.-Age,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-Age-Mortgage-Securities.Account,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
testData$Preds = predict(model1,testData)
View(testData)
View(testData)
testData$Preds = predict(model1,testData, type = 'response')
save.image("D:/Learnings/DataScience/ML/Logistic/UniversalBankData.RData")
load("D:/Learnings/DataScience/ML/Logistic/UniversalBankData.RData")
View(dataset)
View(dataset)
View(dataset2)
View(dataset2)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
dataset2 = dataset
names(dataset2)
#Assigning correct datatypes
str(dataset2)
dataset2$ZIP.Code = as.factor(dataset2$ZIP.Code)
dataset2$Personal.Loan = as.factor(dataset2$Personal.Loan)
#removing unnecessary columns
x = c(1)
dataset2 = dataset[,-x]
names(dataset2)
# Correlation
View(cor(dataset2))
names(dataset2)
cor(dataset2)
library(corrplot)
corrplot(cor(dataset2), 'number') # Drop Age
#train test split
set.seed(111)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
model1 = glm(Personal.Loan~.,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
dataset2$Age = NULL
#train test split
set.seed(111)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
#model build
dataset2$Personal.Loan
model1 = glm(Personal.Loan~.,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage-CCAvg,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
testData$Preds = predict(model1,testData, type = 'response')
View(testData)
View(testData)
testData$Preds1 = ifelse(testData$Preds > 0.5 , 1, 0)
cm = table(testData$Personal.Loan, testData$Preds1, dnn = c('Acts','Preds'))
cm
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage-CCAvg,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
library(MASS)
data("Boston")
?Boston
View(Boston)
str(Boston)
bostondata = data("Boston")
View(bostondata)
bostondata = Boston
str(bostondata)
View(cor(bostondata))
library(corrplot)
corrplot(cor(bostondata), 'number')
boxplot(bostondata)
boxplot(bostondata$crim)
x = summary(bostondata$crim)
top=x[5]+(1.5*IQR(bostondata$crim)) #top
x
bostondata$crim = ifelse(bostondata$crim > top, top, bostondata$crim)
boxplot(bostondata$crim)
boxplot(bostondata)
boxplot(bostondata$zn)
boxplot(bostondata$zn)
x = summary(bostondata$zn)
top=x[5]+(1.5*IQR(bostondata$zn)) #top
bottom=x[2]-(1.5*IQR(bostondata$zn))
bostondata$zn = ifelse(bostondata$zn > top, top, bostondata$zn)
boxplot(bostondata$zn)
boxplot(bostondata)
bostondata$black = ifelse(bostondata$black > top, top, bostondata$black)
boxplot(bostondata$black)
bostondata$black = Boston$black
boxplot(bostondata$black)
x = summary(bostondata$black)
top=x[5]+(1.5*IQR(bostondata$black)) #top
bottom=x[2]-(1.5*IQR(bostondata$black))
bostondata$black = ifelse(bostondata$black > top, top, bostondata$black)
boxplot(bostondata$black)
boxplot(bostondata$black)
x = summary(bostondata$black)
x
top=x[5]+(1.5*IQR(bostondata$black)) #top
boxplot(bostondata$black)
x = summary(bostondata$black)
top=x[5]+(1.5*IQR(bostondata$black)) #top
bottom=x[2]-(1.5*IQR(bostondata$black))
bostondata$black = ifelse(bostondata$black < bottom, bottom, bostondata$black)
boxplot(bostondata$black)
MinMaxScale <- function(x)
{
return((x- min(x)) /(max(x)-min(x)))
}
bostondata = as.data.frame(lapply(bostondata,MinMaxScale))
View(bostondata)
View(bostondata)
summary(bostondata)
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = mean(clust$withinss)/clust$betweenss
}
ss
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss[i] = mean(clust$withinss)/clust$betweenss
}
ss
plot(2:15,ss)
plot(2:15,ss, type = 'l')
plot(2:16,ss, type = 'l')
# Clustering
ss = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = mean(clust$withinss)/clust$betweenss
}
ss
# Clustering
ss = c()
# Clustering
ss = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
}
ss
plot(2:16,ss, type = 'l')
plot(2:15,ss, type = 'l')
plot(2:16,ss, type = 'l')
plot(2:15,ss, type = 'l')
ss
# Clustering
ss = c()
for (i in 2) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
}
ss
# Clustering
ss = c()
for (i in 2:3) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
}
ss
# Clustering
ss = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i] = mean(clust$withinss)/clust$betweenss
}
# Clustering
ss = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1 = mean(clust$withinss)/clust$betweenss
}
ss
# Clustering
ss = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i] = mean(clust$withinss)/clust$betweenss
}
ss1
plot(2:15,ss1, type = 'l')
plot(2:16,ss1, type = 'l')
# Clustering
ss = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i-1] = mean(clust$withinss)/clust$betweenss
}
ss
ss1
plot(2:15,ss, type = 'l')
# Clustering
ss = c()
ss1 = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i-1] = mean(clust$withinss)/clust$betweenss
}
ss
ss1
# Clustering
ss = c()
ss1 = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i] = mean(clust$withinss)/clust$betweenss
}
ss
ss1
# Clustering
ss = c()
ss1 = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i-1] = mean(clust$withinss)/clust$betweenss
}
ss
ss1
plot(2:15,ss, type = 'l')
plot(2:15,ss1, type = 'l')
clust = kmeans(x = bostondata, centers = 5)
clust$centers
clust$cluster
bostondata$Cluster = clust$cluster
?Boston
clust$centers
library(MASS)
data("Boston")
bostondata = Boston
?Boston
View(bostondata)
str(bostondata)
# checking Correlation
View(cor(bostondata))
library(corrplot)
corrplot(cor(bostondata), 'number')
MinMaxScale <- function(x)
{
return((x- min(x)) /(max(x)-min(x)))
}
bostondata = as.data.frame(lapply(bostondata,MinMaxScale))
summary(bostondata)
# Clustering
ss = c()
ss1 = c()
for (i in 2:15) {
clust = kmeans(x = bostondata, centers = i)
ss = c(ss, mean(clust$withinss)/clust$betweenss)
ss1[i-1] = mean(clust$withinss)/clust$betweenss # another way
}
ss
ss1
plot(2:15,ss, type = 'l')
plot(2:15,ss1, type = 'l')
clust = kmeans(x = bostondata, centers = 6)
clust$centers
bostondata$Cluster = clust$cluster
?boston
?Boston
save.image("D:/Learnings/DataScience/ML/Clustering/kMeanClusteringBostonData.RData")
log2(9/14)
-(9/14*log2(9/14) + 5/14*log2(5/14))
((3/7*log2(3/7)+4/7*log2(4/7))+(6/7*log2(6/7)+1/7*log2(1/7)))
1.576901/2
setwd("D:/Learnings/DataScience/ML/Supervised/Decision Tree")
data1 = read.csv('universalBank.csv')
View(data1)
data1$ID = NULL
str(data1)
data1$Personal.Loan = as.factor(data1$Personal.Loan)
data1$Securities.Account = as.factor(data1$Securities.Account)
data1$CD.Account   = as.factor(data1$CD.Account)
data1$Online   = as.factor(data1$Online)
data1$CreditCard    = as.factor(data1$CreditCard)
data1$Education    = as.factor(data1$Education)
names(data1)
summary(data1)
#Train and Test split
set.seed(567)
rows = 1:nrow(data1)
trainRows = sample(rows,round(0.7*nrow(data1)))
trainData = data1[trainRows,]
testData = data1[-trainRows,]
dtree1 = rpart(Personal.Loan~.,data = trainData,control=c(cp=0.0001,maxdepth=5))
#reduce cp to increase complexity
plotcp(dtree1)
#Decision Tree
#install.packages('rpart')
library(rpart)
dtree1 = rpart(Personal.Loan~.,data = trainData,control=c(cp=0.0001,maxdepth=5))
#reduce cp to increase complexity
plotcp(dtree1)
#D Tree Plot
#install.packages('rpart.plot')
library(rpart.plot)
rpart.plot(dtree1)
#Prediction
preds = predict(dtree1, testData)
#Prediction
preds = predict(dtree1, testData)
preds = as.data.frame(preds)
#testData$Predsclass = preds
head(preds)
testData$Predsclass = ifelse(preds$`1`> 0.5 , 1, 0)
table(testData$Predsclass)
#Confusion Matrix
table(testData$Personal.Loan,testData$Predsclass,dnn = c('Acts','Preds'))
#ROC Curve
#install.packages('ROCR')
library(gplots)
library(ROCR)
pred_ROCR = prediction(testData$Predsclass, testData$Personal.Loan)
perf_ROCR = performance(pred_ROCR, 'tpr', 'fpr')
plot(perf_ROCR,colorize = T, print.cutoffs.at=seq(0,1,by=0.1),
text.adj=c(1.2,1.2), avg="threshold", lwd=3,
main= "ROC")
IrisData = read.csv('Iris.csv')
setwd("D:/Learnings/DataScience/ML/Other Sources")
IrisData = read.csv('Iris.csv')
View(IrisData)
View(IrisData)
workdata = IrisData
#Remove ID
workdata$Id = NULL
View(workdata)
str(workdata)
#Train and test data split
set.seed(143)
trainrows = sample(nrow(workdata),round(0.70*nrow(workdata)))
traindata = workdata[trainrows,]
testdata = workdata[-trainrows,]
#Regression Model
mymodel = glm(Species~., data = traindata, family = binomial(link = "logit"))
levels(workdata$Species)
levels(workdata$Species) = c(1,2,3)
levels(workdata$Species)
#setosa - 1     versocolor - 2    Virginica - 3
workdata$Species = as.numeric(workdata$Species)
#Train and test data split
set.seed(143)
trainrows = sample(nrow(workdata),round(0.70*nrow(workdata)))
traindata = workdata[trainrows,]
testdata = workdata[-trainrows,]
#Regression Model
mymodel = glm(Species~., data = traindata, family = binomial(link = "logit"))
?nnet
IrisData = read.csv('Iris.csv')
workdata = IrisData
#Remove ID
workdata$Id = NULL
str(workdata)
#levels(workdata$Species) = c(1,2,3)
#setosa - 1     versocolor - 2    Virginica - 3
#workdata$Species = as.numeric(workdata$Species)
library(dummies)
df = dummy.data.frame(workdata)
View(df)
workdata = dummy.data.frame(workdata)
remove(df)
IrisData = read.csv('Iris.csv')
workdata = IrisData
workdata$Id = NULL
library(rpart)
dtree1 = rpart(Species ~ ., data = workdata, control = c(cp = 0.001, maxdepth = 5))
plot(dtree1)
library(rpart.plot)
rpart.plot(dtree1)
install.packages('nnet')
#install.packages('nnet')
?multinom
#install.packages('nnet')
?nnet
#install.packages('nnet')
library(nnet)
?multinom()
set.seed(143)
trainrows = sample(nrow(workdata),round(0.70*nrow(workdata)))
traindata = workdata[trainrows,]
testdata = workdata[-trainrows,]
mulmodel = multinom(Species ~. , data = traindata)
summary(mulmodel)
testdata$preds = mulmodel(data = testdata)
testdata$preds = predict(mulmodel, data = testdata)
testdata$preds = predict(mulmodel,testdata)
View(testdata)
head(pp <-fitted(mulmodel))
testdata$Err = ifelse(testdata$Species == testdata$preds, 0, 1)
table(testdata$Err)
testdata[testdata$Err == 1,]
IrisData = read.csv('Iris.csv')
workdata = IrisData
workdata$Id = NULL
set.seed(143)
set.seed(140)
trainrows = sample(nrow(workdata),round(0.70*nrow(workdata)))
traindata = workdata[trainrows,]
testdata = workdata[-trainrows,]
dtree1 = rpart(Species ~ ., data = traindata, control = c(cp = 0.001, maxdepth = 5))
library(rpart.plot)
rpart.plot(dtree1)
preds = predict(dtree1, testdata)
preds
head(preds)
tail(preds)
tail(preds$'1')
tail(preds$Iris-setosa)
preds = as.data.frame(preds)
head(preds)
tail(preds$Iris-setosa)
tail(preds)
tail(preds$'1')
View(preds)
testdata$MyPred = ifelse(preds$`Iris-setosa` > preds$`Iris-versicolor`, ifelse(preds$`Iris-setosa` > preds$`Iris-virginica`, 'Iris-setosa','Iris-virginica'), ifelse(preds$`Iris-versicolor` > preds$`Iris-virginica`, 'Iris-versicolor','Iris-virginica') )
View(testdata)
testdata$Err = ifelse(testdata$Species == testdata$MyPred, 0, 1)
table(testdata$Err)
testdata[testdata$Err == 1,]
