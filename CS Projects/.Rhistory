preds = predict(model1,testData)
preds
preds = predict(model1,testData, type = 'response')
preds
preds = ifelse(preds > 0.5, 1, 0)
preds
table(preds, testData$survived, dnn = c('preds','actuals'))
load("D:/Learnings/DataScience/ML/Logistic/LogisticData1.RData")
#Contigency table
table(preds, testData$survived, dnn = c('preds','actuals'))
summary(model1)
dataset = read.csv('D:\\Learnings\\DataScience\ML\\Logistic\\universalBank.csv')
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
View(dataset)
View(dataset)
summary(dataset)
table(dataset)
names(dataset)
x = c(1,5)
dataset2 = dataset[,-x]
View(dataset2)
View(dataset2)
class(dataset)
class(dataset2$Age)
class(dataset2$Experience)
class(dataset2$Education)
table(dataset2$Education)
dataset2$Education = as.factor(dataset2$Education)
class(dataset2$Education)
class(dataset2$Securities.Account)
dataset2$Securities.Account = as.factor(dataset2$Education)
class(dataset2$Securities.Account)
table(dataset2$Securities.Account)
class(dataset2$CD.Account)
table(dataset2$CD.Account)
dataset2$CD.Account = as.factor(dataset2$Education)
class(dataset2$CD.Account)
table(dataset2$CD.Account)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
x = c(1,5)
dataset2 = dataset[,-x]
names(dataset2)
class(dataset2$Education)
table(dataset2$Education)
dataset2$Education = as.factor(dataset2$Education)
class(dataset2$Education)
table(dataset2$Education)
class(dataset2$Securities.Account)
table(dataset2$Securities.Account)
dataset2$Securities.Account = as.factor(dataset2$Securities.Account)
class(dataset2$Securities.Account)
table(dataset2$Securities.Account)
class(dataset2$CD.Account)
table(dataset2$CD.Account)
dataset2$CD.Account = as.factor(dataset2$CD.Account)
class(dataset2$Online)
table(dataset2$Online)
dataset2$Online = as.factor(dataset2$Online)
class(dataset2$CreditCard)
table(dataset2$CreditCard)
dataset2$CreditCard = as.factor(dataset2$CreditCard)
#Outliers
boxplot(dataset2)
boxplot(dataset2$Income)
y = summary(dataset2$Income)
y
top = y[5] + (1.5 * IQR(dataset2$Income))
top
dataset2$Income = ifelse(dataset2$Income > top, top, dataset2$Income)
boxplot(dataset2$Income)
#Outliers
boxplot(dataset2)
boxplot(dataset2$CCAvg)
y = summary(dataset2$CCAvg)
y
top = y[5] + (1.5 * IQR(dataset2$CCAvg))
dataset2$CCAvg = ifelse(dataset2$CCAvg > top, top, dataset2$CCAvg)
boxplot(dataset2$CCAvg)
#Outliers
boxplot(dataset2)
boxplot(dataset2$Personal.Loan)
y = summary(dataset2$Personal.Loan)
y
#Outliers
boxplot(dataset2)
y = summary(dataset2$Mortgage)
boxplot(dataset2$Mortgage)
y = summary(dataset2$Mortgage)
top = y[5] + (1.5 * IQR(dataset2$Mortgage))
dataset2$Mortgage = ifelse(dataset2$Mortgage > top, top, dataset2$Mortgage)
boxplot(dataset2$Mortgage)
#Outliers
boxplot(dataset2)
boxplot(dataset2$Personal.Loan)
y = summary(dataset2$Personal.Loan)
top = y[5] + (1.5 * IQR(dataset2$Personal.Loan))
dataset2$Personal.Loan = ifelse(dataset2$Personal.Loan > top, top, dataset2$Personal.Loan)
boxplot(dataset2$Personal.Loan)
#Outliers
boxplot(dataset2)
# Correlation
View(cor(dataset2))
library(corrplot)
corrplot(cor(dataset2), 'circle')
cor(dataset2)
names(datase)
names(dataset2)
cor(dataset2[,c(1,2,3,4,5,7,8)])
class(dataset2$Personal.Loan)
cor(dataset2[,c(1,2,3,4,5,7,8)])
cor(dataset2[,c(1,2,3,4,5,7)])
corrplot(cor(dataset2[,c(1,2,3,4,5,7)]), 'circle')
corrplot(cor(dataset2[,c(1,2,3,4,5,7)]), 'numeric')
corrplot(cor(dataset2[,c(1,2,3,4,5,7)]), 'number')
dataset3 = dataset2[,-c(1)]
View(dataset3)
View(dataset3)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
chisq.test(dataset2$Personal.Loan, dataset2$Education)
class(dataset2$Education)
table(dataset2$Education)
table(dataset2$Personal.Loan)
table(dataset$Personal.Loan)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
#removing unnecessary columns
x = c(1,5)
dataset2 = dataset[,-x]
names(dataset2)
#Assigning correct datatypes
class(dataset2$CreditCard)
#Assigning correct datatypes
class(dataset3$CreditCard)
table(dataset3$Personal.Loan)
dataset3$Personal.Loan = dataset$Personal.Loan
table(dataset3$Personal.Loan)
chisq.test(dataset3$Personal.Loan, dataset3$Education)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
#removing unnecessary columns
x = c(1,5)
dataset2 = dataset[,-x]
names(dataset2)
View(dataset)
View(dataset)
View(dataset2)
View(dataset2)
#Assigning correct datatypes
class(dataset2$CreditCard)
table(dataset2$CreditCard)
dataset2$CreditCard = as.factor(dataset2$CreditCard)
#Assigning correct datatypes
class(dataset2$Online)
table(dataset2$Online)
dataset2$Online = as.factor(dataset2$Online)
#Assigning correct datatypes
class(dataset2$CD.Account)
table(dataset2$CD.Account)
#Assigning correct datatypes
class(dataset2$CD.Account)
table(dataset2$CD.Account)
dataset2$CD.Account = as.factor(dataset2$CD.Account)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
#removing unnecessary columns
x = c(1,5)
dataset2 = dataset[,-x]
names(dataset2)
#Assigning correct datatypes
str(dataset2)
#Outliers
boxplot(dataset2)
boxplot(dataset2$Personal.Loan)
y = summary(dataset2$Income)
top = y[5] + (1.5 * IQR(dataset2$Income))
dataset2$Income = ifelse(dataset2$Income > top, top, dataset2$Income)
boxplot(dataset2$CCAvg)
y = summary(dataset2$CCAvg)
top = y[5] + (1.5 * IQR(dataset2$CCAvg))
dataset2$CCAvg = ifelse(dataset2$CCAvg > top, top, dataset2$CCAvg)
boxplot(dataset2$CCAvg)
#Outliers
boxplot(dataset2)
y = summary(dataset2$Mortgage)
boxplot(dataset2$Mortgage)
y = summary(dataset2$Mortgage)
top = y[5] + (1.5 * IQR(dataset2$Mortgage))
dataset2$Mortgage = ifelse(dataset2$Mortgage > top, top, dataset2$Mortgage)
names(dataset2)
cor(dataset2[,c(1,2,3,4,5,6,7,8)])
cor(dataset2)
corrplot(cor(dataset2), 'number')
#train test split
set.seed(111)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
model1 = glm(Personal.Loan~.-Age,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-Age-Mortgage-Securities.Account,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
testData$Preds = predict(model1,testData)
View(testData)
View(testData)
testData$Preds = predict(model1,testData, type = 'response')
save.image("D:/Learnings/DataScience/ML/Logistic/UniversalBankData.RData")
load("D:/Learnings/DataScience/ML/Logistic/UniversalBankData.RData")
View(dataset)
View(dataset)
View(dataset2)
View(dataset2)
dataset = read.csv('D:\\Learnings\\DataScience\\ML\\Logistic\\universalBank.csv')
summary(dataset)
names(dataset)
dataset2 = dataset
names(dataset2)
#Assigning correct datatypes
str(dataset2)
dataset2$ZIP.Code = as.factor(dataset2$ZIP.Code)
dataset2$Personal.Loan = as.factor(dataset2$Personal.Loan)
#removing unnecessary columns
x = c(1)
dataset2 = dataset[,-x]
names(dataset2)
# Correlation
View(cor(dataset2))
names(dataset2)
cor(dataset2)
library(corrplot)
corrplot(cor(dataset2), 'number') # Drop Age
#train test split
set.seed(111)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
model1 = glm(Personal.Loan~.,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
dataset2$Age = NULL
#train test split
set.seed(111)
nrows = 1:nrow(dataset2)
trainRows = sample(nrows, round(0.7*nrow(dataset2)))
trainData = dataset2[trainRows,]
testData = dataset2[-trainRows,]
#model build
dataset2$Personal.Loan
model1 = glm(Personal.Loan~.,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage-CCAvg,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
testData$Preds = predict(model1,testData, type = 'response')
View(testData)
View(testData)
testData$Preds1 = ifelse(testData$Preds > 0.5 , 1, 0)
cm = table(testData$Personal.Loan, testData$Preds1, dnn = c('Acts','Preds'))
cm
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage-CCAvg,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
model1 = glm(Personal.Loan~.-Experience-ZIP.Code-Mortgage,
data=trainData,
family = binomial(link = "logit"))
summary(model1)
setwd("D:/Learnings/DataScience/ML/CS Projects")
getwd()
churn_mv=read.csv("churn_MV.csv")
####### Several functions for different tasks #######
funColToFactos<-function(x){
x=as.factor(x)
}
rsme<-function(a,p){
sqrt(mean((a-p)**2))
}
outlierRemoval<-function(x){
q3=quantile(x, 0.75)
q1=quantile(x, 0.25)
range= 1.5*IQR(x)
upperbound=q3+range
lowerBound=q1-range
x=ifelse((x>upperbound),upperbound,ifelse((x<lowerBound),lowerBound,x))
return(x)
}
## minmax scalling
minmaxScale<- function(x)
{
return((x-min(x))/(max(x)-min(x)))
}
names=colnames(churn_mv)
charCols=c("Churn","Intl.Plan","VMail.Plan","State","Area.Code","Phone")
?setdiff
numCols=setdiff(names,charCols)
numCols
churn_mv[,charCols]=lapply(churn_mv[,charCols], funColToFactos)
str(churn_mv)
## remove the null values if it has on the target variable
churn_mv=churn_mv[!is.na(churn_mv$CustServ.Calls),]
str(churn_mv)
View(churn_mv)
View(churn_mv)
dayMean=mean(churn_mv$Day.Charge)
dayMedian=median(churn_mv$Day.Charge)
churn_mv$dayMean=ifelse(is.na(churn_mv$Daily.Charges.MV),dayMean,churn_mv$Daily.Charges.MV)
churn_mv$dayMedian=ifelse(is.na(churn_mv$Daily.Charges.MV),dayMedian,churn_mv$Daily.Charges.MV)
rsmeMean=rsme(churn_mv$Day.Charge,churn_mv$dayMean)
rsmeMedian=rsme(churn_mv$Day.Charge,churn_mv$dayMedian)
rsmeMean
rsmeMedian
## by observing rsme mean and rsme median we can consider the value which is lower so mean is good for replacing the null values
## removing daily.charges.mv column because we have the original data in day.charges from here on wards we are going to use day.charges column
churn_mv$Daily.Charges.MV=NULL
numCols= numCols[!(numCols %in% "Daily.Charges.MV")]
## Step 4:- Replacing outlier values with the whisker values
boxplot(churn_mv$Eve.Mins)
churn_mv[,numCols]=lapply(churn_mv[,numCols], outlierRemoval)
## Step 4:- Replacing outlier values with the whisker values
boxplot(churn_mv$Eve.Mins)
## inorder to find scalling and correlation we need to seperate the dataset into two different columns
churn_num=churn_mv[,numCols]
churn_cat=churn_mv[,charCols]
minmaxData=as.data.frame(lapply(churn_num[,-7], minmaxScale))
minmaxData$CustServ.Calls=churn_num$CustServ.Calls
minmaxBind=cbind(minmaxData,churn_cat)
## z score ##
zscoreData=as.data.frame(scale(churn_num[,-7]))
zscoreData$CustServ.Calls=churn_num$CustServ.Calls
zscoreBind=cbind(zscoreData,churn_cat)
## 1. Correlation between continous variable
cor(churn_num)
install.packages("corrplot")
library("corrplot")
corrplot(cor(churn_num))
=mean(churn_mv$Day.Charge)
dayMean
View(churn_num)
View(churn_num)
corrplot(cor(churn_num))
chisq.test(table(churn_cat$Churn,churn_cat$Intl.Plan)) ## p= 2.2e-16 ## both are dependent
chisq.test(table(churn_cat$Churn,churn_cat$VMail.Plan)) ## p= 5.151e-09 ## both are dependent
chisq.test(table(churn_cat$Intl.Plan,churn_cat$VMail.Plan)) ## p= 0.7785 ## both are independent
summary(aov(minmaxBind$VMail.Message~minmaxBind$VMail.Plan)) # p=2e-16 # both are dependent
summary(aov(minmaxBind$Account.Length~minmaxBind$VMail.Plan)) # p=0.836 # both are undependent
minmaxBind$Day.Charge=NULL
minmaxBind$Eve.Charge=NULL
minmaxBind$Night.Charge=NULL
minmaxBind$Intl.Charge=NULL
minmaxBind$Churn=NULL
minmaxBind$VMail.Message=NULL
minmaxBind$Phone=NULL
minmaxBind$Area.Code=NULL
minmaxBind$State=NULL
## Step 7:- EDA
## we need to do the EDA for univeriant, bi-variant, multivariant analysis
## we need to findout the inference and verify after the step 9
boxplot(minmaxData$Account.Length)
boxplot(minmaxBind$Intl.Plan,minmaxBind$CustServ.Calls)
library(ggplot2)
ggplot(minmaxBind,aes(x=Intl.Plan,y=CustServ.Calls))+geom_boxplot()
## Step 8:- Sampling
## generating train and test data for the linear regrassion model
## Randome sampling
set.seed(675) ## for generating the random data same for everytime
## Step 8:- Sampling
## generating train and test data for the linear regrassion model
## Randome sampling
set.seed(675) ## for generating the random data same for everytime
randomIds = sample( nrow(minmaxBind), nrow(minmaxBind)*0.8)
trainData = minmaxBind[randomIds,]
testData = minmaxBind[-randomIds,]
## stratified sampling
install.packages("caTools")
library(caTools)
train_rows=sample.split(minmaxBind$CustServ.Calls,SplitRatio = 0.8)
trainData=minmaxBind[train_rows,]
testData=minmaxBind[!train_rows,]
lin_model=lm(CustServ.Calls~.,data = trainData)
summary(lin_model)
testData$predzsc = predict(lin_model, newdata=testData )
testData$error = testData$CustServ.Calls - testData$predzsc
testData$error_sq = testData$error ** 2
rmse = sqrt(mean(testData$error_sq))
rmse
zscoreBind$Day.Charge=NULL
zscoreBind$Eve.Charge=NULL
zscoreBind$Night.Charge=NULL
zscoreBind$Intl.Charge=NULL
zscoreBind$Churn=NULL
zscoreBind$VMail.Message=NULL
zscoreBind$Phone=NULL
zscoreBind$Area.Code=NULL
zscoreBind$State=NULL
## Sampling with zscore dataframe
## Random Sampling
set.seed(674) ## for generating the random data same for everytime
randomIds = sample( nrow(zscoreBind), nrow(zscoreBind)*0.8)
trainData = zscoreBind[randomIds,]
testData = zscoreBind[-randomIds,]
## stratified sampling
train_rows=sample.split(zscoreBind$CustServ.Calls,SplitRatio = 0.8)
trainData=zscoreBind[train_rows,]
testData=zscoreBind[!train_rows,]
lin_model=lm(CustServ.Calls~.,data = trainData)
summary(lin_model)
testData$predzsc = predict(lin_model, newdata=testData )
testData$error = testData$CustServ.Calls - testData$predzsc
testData$error_sq = testData$error ** 2
rmse = sqrt(mean(testData$error_sq))
rmse  # RMSE= 1.1529 with random sampling
## RMSE = 1.087 random sampling with minmax scalling
## RMSE = 1.087 random sampling with minmax scalling
## RMSE = 1.106492 stratified sampling with minmax scalling
## RMSE = 1.087 random sampling with minmax scalling
## RMSE = 1.106492 stratified sampling with minmax scalling
## RMSE= 1.1529 random sampling with zscore
###### Observations #######
###### Observations #######
# Minmax scalling is giving better results then zscore
#################################################################################
#################################################################################
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#                Considering daily.charges.mv as target                         #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#                Considering daily.charges.mv as target                         #
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#                Considering daily.charges.mv as target                         #
#                                                                               #
#                                                                               #
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#                Considering daily.charges.mv as target                         #
#                                                                               #
#                                                                               #
#                                                                               #
#################################################################################
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#                Considering daily.charges.mv as target                         #
#                                                                               #
#                                                                               #
#################################################################################
#                                                                               #
#                                                                               #
#                                                                               #
#                                                                               #
#                Considering daily.charges.mv as target                         #
#                                                                               #
#                                                                               #
#                                                                               #
#################################################################################
save.image("D:/Learnings/DataScience/ML/CS Projects/CS1_SaiKrupaFileData.R.RData")
